---
title: "P8451_final_ML"
author: "Ruixi Li"
date: "2024-03-26"
output: html_document
---

```{r library, include=FALSE}
library(tidyverse)
library(caret)
library(rpart.plot)
library(vcd)
library(reshape2)

```

# Research Question

My research question is to generate a hypotheses regarding a wide range of prenatal lifestyles and chemical exposures affect birth outcome(measured by birthweight) using data-driven methods. 

# Load .Rdata file and Data Preparation
rexpose package were introduced here in hope of characterization more easily. But it seemed too rigid to be applied to datasets containing both continuous and categorical variables. So I only deal with continuous exposome with this package.

```{r data preparation, warning=FALSE, message=FALSE}
library(rexposome)
args(loadExposome)

# Load data using path of where file is stored
load("exposome.RData")

# modify the dataframes to fit with the data format required by package 'rexposome'.
## merge covariates and phenotype, phenotype only has birthweight.
phenotype = phenotype |> select(ID, e3_bw)
cov_phe = inner_join(covariates, phenotype, by = "ID")

## I am planning on exploring the effect of prenatal exposome towards babies' birth weight. So I just removed all postnatal exposure.


### tailor exposome into all continuous prenatal exposome, corresponding with codebook
pre = codebook |> filter(period == "Pregnancy")
name = rownames(pre)
pre_exp = exposome |> select(ID,any_of(name)) 
pre_exp_cont = pre_exp |> select(where(is.numeric))
filtered_name = colnames(pre_exp_cont) 
### tailor the codebook(description containing all prenatal exposome description info, including family-each row is an exposure)
exp_description <- codebook |>  filter(variable_name %in% filtered_name) 
### Since codebook's row name was originally the exposure names, I just removed the 'variable name' column 
exp_description <- exp_description[,-1]
### let ID be pre_exp's rowname and remove the id column
rownames(pre_exp) <- pre_exp_cont[,1]
pre_exp_cont <- pre_exp_cont[,-1]
### let ID be cov_phe's rowname and remove the id column
rownames(cov_phe) <- cov_phe[,1]
cov_phe <- cov_phe[,-1]


# get the object fit with rexposome
exp <- loadExposome(
    exposures = pre_exp_cont, 
    description = exp_description, 
    phenotype = cov_phe
)
# give an overall look at the exposome of interest
skimr::skim(pre_exp)
```

# Data Exploration

## 1. Covariates and phenotypes
1. Since this dataset is a combine data from 6 cohorts, I would explore population characteristics(covariates) and outcomes(phenotypes) by cohorts.
```{r missing1}
plotMissings(exp, set = "phenotypes")
#tableMissings(exp, set = "phenotypes", output = "n")
```

### categorical variables

```{r cate_cov_phe, warning=FALSE, message=FALSE}
cate_cov_phe = cov_phe |> select(where(is.factor))

# Frequency table
frequency_tables_cov_phe <- cate_cov_phe %>% map(~ as.data.frame(table(.x)))
frequency_tables_cov_phe |>knitr::kable()# name of variables in these freq tables are displayed in the plot below

# Difference by cohort
cate_cov_phe_summ = cate_cov_phe %>%
  pivot_longer(cols = -h_cohort, names_to = "covariate", values_to = "value") %>%
  group_by(h_cohort, covariate,value) %>%
  summarize(n = n(), .groups = 'drop') %>%
  ungroup() 

cate_cov_phe_summ %>%
  ggplot(aes(x = h_cohort, y = n, color = value)) +
  geom_point() +
  geom_smooth(aes(group=value), method = "loess", se = FALSE) + 
  facet_grid(. ~ covariate) +
  theme_minimal() +  # For a cleaner look
  labs(x = "Cohort", y = "Count", title = "Summary by Cohort and Covariate") 

```

### continuous variables

```{r cont_cov_phe}

cont_cov_phe = cov_phe|> select(where(is.numeric))

summary_table_cov_phe <- cont_cov_phe %>%
  summarise(across(where(is.numeric), list(
    Mean = ~mean(.x, na.rm = TRUE),
    SD = ~sd(.x, na.rm = TRUE),
    Median = ~median(.x, na.rm = TRUE),
    IQR = ~IQR(.x, na.rm = TRUE)
  ))) |>
  pivot_longer(
    cols = everything(), 
    names_to = c(".value", "Statistic"), 
    names_pattern = "(.*)_(.*)"
  ) 
summary_table_cov_phe|> knitr::kable()

# I specify the continuous variables' names in 'name' vector to add h_cohort in this dataset(I want to assess if there's difference between cohorts-especially the exposome)
name_cont_cov_phe = colnames(cont_cov_phe)[-1]
results_cov_phe = cov_phe |> select(h_cohort, any_of(name_cont_cov_phe))

results_summary_cov_phe = results_cov_phe %>%
  group_by(h_cohort) %>%
  summarize(across(where(is.numeric), 
                   list(mean = ~mean(.x, na.rm = TRUE), 
                        std = ~sd(.x, na.rm = TRUE)))) 

# Since birthweight is too large(also my outcome), I displayed it separately.
results_cov_phe |> ggplot(aes(x=h_cohort, y=e3_bw)) + geom_boxplot() +
  labs(x = "Cohort", y = "Birthweight(g)", title = "Birthweight of children by Cohort") 

results_cov_phe_nobw = results_cov_phe |> select(-e3_bw)

# difference across cohorts
results_melted_cov_phe = melt(results_cov_phe_nobw)
results_melted_cov_phe |>
  ggplot(aes(x=h_cohort, y=value, fill=variable)) + geom_boxplot() + facet_wrap(~variable)+
  labs(x = "Cohort", y = "Covariates and phenotypes", title = "Covariates and phenotypes by Cohort") 

```

## 2. Exposome

2. Look at the exposome characteristics by family and the correlation between exposome

```{r missing2}
#tableMissings(exp, set = "exposures", output = "n")
plotMissings(exp, set = "exposures")

```
The current exposome data has no missing in the exposures nor in the phenotypes


### continuous
```{r}
# exposome behavior
# plotFamily(exp, family = "all") generate error message, I don't know why, the for loop didn't work either. it seemed like the 'build environment' had a mixed falimy
plotFamily(exp, family = "Air Pollution")
# plotFamily(exp, family = "Built environment")
plotFamily(exp, family = "Metals")
plotFamily(exp, family = "Meteorological")
plotFamily(exp, family = "Natural Spaces")
plotFamily(exp, family = "Noise")
plotFamily(exp, family = "Organochlorines")
plotFamily(exp, family = "Organophosphate pesticides")
plotFamily(exp, family = "Polybrominated diphenyl ethers (PBDE)")
plotFamily(exp, family = "Per- and polyfluoroalkyl substances (PFAS)")
plotFamily(exp, family = "Phenols")
plotFamily(exp, family = "Phthalates")
plotFamily(exp, family = "Tobacco Smoke")
plotFamily(exp, family = "Traffic")
plotFamily(exp, family = "Water DBPs")

# exposome are not normally distributed
nm <- normalityTest(exp)
table(nm$normality)

# correlation
exp_cr <- correlation(exp, use = "pairwise.complete.obs", method.cor = "pearson")
plotCorrelation(exp_cr, type = "circos")
plotCorrelation(exp_cr, type = "matrix")
```

# Prepare datasets
```{r final_dataset}
# merge features together
feature = merge(pre_exp,covariates,by="ID") |> select(-c(hs_c_height_None, hs_c_weight_None, hs_child_age_None))
outcome = phenotype |> select(ID, e3_bw)
studydata = merge(feature,outcome,by="ID") 

# keep all interested features, no matter continuous or categorical, in a new dataframe 'rf_ln' for random forest algorithm and classic linear regression 
rf_ln = studydata |> select(-ID)


# transform all categorical variables into dummy variables and keep all features in a dataframe 'la_data' for lasso algorithm
# One-hot encode the categorical variables
la_data <- dummyVars("~ .", data = rf_ln)
la_data <- data.frame(predict(la_data, newdata = rf_ln))
```


# PCA to reduce dimensionality(create a new variable) 

We reduced the dimensionality by conducting a separate PCA within each of the 19 pre-defined exposure groups, and retained only the first principal component for all of them. This way, we created a composite index variable (principal component scores) for each exposure group, and then averaged the scores by cohort to compare the levels. (https://www.sciencedirect.com/science/article/pii/S0160412018316295#t0005)

```{r}
library(FactoMineR)


# get all family of exposome
pre_exp_grp = codebook |> filter(period=="Pregnancy" & !(family %in% c("Covariates", "Phenotype")))
exp_groups = unique(pre_exp_grp$family)

# Transform the nominal variables into binary variables using the dummy variable object
dummies_pre_exp <- dummyVars("~ .", data = pre_exp)
pre_exp_transformed <- data.frame(predict(dummies_pre_exp, newdata = pre_exp))

# Delete the id column of pre_exp
pre_exp_transformed_noid = pre_exp_transformed |> select(-ID)

# conduct PCA within each family iteratively and get a composite index variable (principal component scores) for each exposure group
for (family in exp_groups){
  
  ori_comp_names = codebook |> filter(family==family) |> pull(variable_name)
  ori_comp = pre_exp_transformed_noid |> select(matches(paste0("^", ori_comp_names, ".*")))
  res.pca <- PCA(ori_comp, scale.unit = TRUE, ncp = 5, graph = FALSE)

  # Extracting the first principal component scores
  pc1_scores <- res.pca$ind$coord[, 1]
}


# Add the PCA score to the whole dataset with cohort info
studydata$pc1_score <- pc1_scores

# Averaging the PCA scores by cohort
average_scores_by_cohort <- studydata %>%
  group_by(h_cohort) %>%
  summarise(Average_pc1_Score = mean(pc1_scores, na.rm = TRUE))

average_scores_by_cohort
```

 **In a nutshell, the final dataset 'rf_ln' has 1 outcome *e3bw*, 10 covariates that were know at birth(excluding hs_c_height_None, hs_c_weight_None, hs_child_age_None) and 88 prenatal exposures.** There's no missing or duplicate in this dataset. All variables were correctly classified as numeric or factor. **To better application of some algorithms, some transformation of the dataset is needed(e.g. 'la_data')** 
 
EDA findings:

1. Some covariates (e.g. education and nativity of parents) might different across cohorts. We should assess the heterogenitity before we could pool the data from six cohorts. But due  to limited time, I just assumed that we can pool them together and continue the further application od machine learning.

2. exposomes vary in their level even though they are from the same family, so we need to do centering and scaling. Using a innovative methods of PCA, we can compare the overall level of exposome to see if there's cohort effect. 

3. More detail on PCA that created a new variable that not involved in our main analysis:

By conducting PCA separately within each family, we aimed to:

* Reduce Dimensionality: We extracted the first principal component (PC) from each family to summarize the key variance within that family. This step reduces the complexity of the dataset while retaining critical information.
* Increase Comparability and Interpretability: Separate PCAs allowed the researchers to better understand and interpret the main drivers of variability within each exposure family. This approach helps in comparing levels of exposure across different cohorts.


```{r partition}
#Partition data for use in demonstration
set.seed(123)
train.indices<-createDataPartition(y=rf_ln$e3_bw,p=0.7,list=FALSE)
train.data<-rf_ln[train.indices, ]
test.data<-rf_ln[-train.indices, ]

set.seed(123)
control <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
```


# LASSO

```{r lasso}
la.model<- train(
                  e3_bw ~., 
                  data = train.data, 
                  method = "glmnet",
                  trControl =  control, 
                  preProc = c("center", "scale"),
                  tuneGrid = expand.grid(alpha = 1, 
                                         lambda = exp(seq(3, -3, length = 100)))
                )

coef(la.model$finalModel, la.model$bestTune$lambda)

print(la.model$bestTune)
print(la.model$results$RMSE[which.min(la.model$results$RMSE)])

```





# Random Forest


```{r random forest}
# For random forest with lots of features, mtry = p(the number of all features)/3 tend to be a good default mtry for regression. mtry = sqrt(p) is a good default for classification. (https://scholarworks.utep.edu/cgi/viewcontent.cgi?article=4251&context=open_etd)

feat.count<-c(ncol(rf_ln)/3, ncol(rf_ln)/2, ncol(rf_ln)-1)

grid.rf<-expand.grid(mtry=round(feat.count))

tree.num<-seq(100,500, by=200)

results.trees<-list()

for (ntree in tree.num){
 set.seed(123)
  rf.model<-train(e3_bw ~ ., 
                 data=train.data, 
                 method="rf", 
                 metric="RMSE", 
                 tuneGrid=grid.rf, 
                 importance=TRUE, 
                 ntree=ntree)
index<-toString(ntree)
results.trees[[index]]<-rf.model$results
}
plot(rf.model)
rf.model$results


output.rf<-bind_rows(results.trees, .id = "ntrees")
best.tune<-output.rf[which.max(output.rf[,"mtry"]==51),]
best.tune$mtry
mtry.grid<-expand.grid(.mtry=best.tune$mtry)
set.seed(123)
    rf.model.bt<-train(
                      e3_bw~., 
                      data=train.data, 
                      method="rf", 
                      trControl=control, 
                      metric="RMSE", 
                      tuneGrid=mtry.grid, 
                      importance=TRUE,
                      ntree=as.numeric(best.tune$ntrees))

    


rf.model.bt$results
rf.model.bt$finalModel
varImp(rf.model.bt)
plot(varImp(rf.model.bt))
```

Although when mtry is close to the number of all features(p), RMSE is the lowest. But it increases the risk of overfitting. What's more, values of mtry that are close to the total number of variables in the model may weaken the forest by making the individual decision trees more correlated; when the decision trees consider similar sets of variables to split on, they are more likely to be similar, even if each is fit to a different bootstrapped data set. Ensemble models usually strive for independence of their members, as that improves predictive ability. We can also see from the plot that the decreasing trend of RMSE flattened after 51. I would choose 51 as my final mtry.


# Linear regression 

```{r linear_reg}

# Initialize a model with all predictors
intercept.model <- lm(e3_bw ~ ., data = rf_ln)

# Both-direction stepwise regression
ln.model <- step(intercept.model, direction = "both", trace = 0)

summary(ln.model)

set.seed(123)


linear.model <- train(
  e3_bw ~ h_fdensity300_preg_Log + h_frichness300_preg_None + 
    h_walkability_mean_preg_None + h_dairy_preg_Ter + h_folic_t1_None + 
    h_meat_preg_Ter + h_pamod_t3_None + hs_cs_m_Log2 + h_temperature_preg_None + 
    hs_dde_madj_Log2 + hs_pcb170_madj_Log2 + hs_dep_madj_Log2 + 
    hs_dmtp_madj_Log2 + hs_pfos_m_Log2 + hs_bupa_madj_Log2 + 
    hs_mepa_madj_Log2 + hs_meohp_madj_Log2 + hs_mibp_madj_Log2 + 
    hs_mnbp_madj_Log2 + e3_asmokcigd_p_None + h_bro_preg_Log + 
    h_cohort + e3_sex_None + h_mbmi_None + hs_wgtgain_None + 
    e3_gac_None + h_edumc_None + h_parity_None,
  data = train.data,
  method = "lm",
  trControl = control,
  preProcess = c("center", "scale")
)

linear.model$results

  
```

I would like to choose linear regression as my final model, since it has the lowest RMSE and interpretable.

```{r Predictions on the test set}
predictions <- predict(linear.model, test.data)
```

```{r Evaluate the model}
results <- postResample(predictions, test.data$e3_bw)
results
```

```{r visualization_linear}

ggplot(data = test.data, aes(x = e3_bw, y = predictions)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", col = "blue") +
  labs(x = "Actual Birthweight", y = "Predicted Birthweight", title = "Linear Model Predictions vs Actual")
```

Model Fit: The fact that the majority of points are clustered around the line suggests that there is a moderate to strong positive linear relationship between the actual and predicted birthweights. However, the model is not perfect, which is expected in most real-world scenarios.
There is some variability in the predictions, as indicated by the scatter of points around the line. Notably, the model seems to underpredict for lower actual birthweights and overpredict for higher actual birthweights, as evidenced by the points below the line on the left and above the line on the right.
