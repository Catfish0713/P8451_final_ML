---
title: "P8451_final_ML"
author: "Ruixi Li"
date: "2024-03-26"
output: html_document
---

# Introduction
Recent studies on prenatal exposure and lifestyle effects on birthweight reveal diverse findings. For instance, prenatal exposure to phthalates is linked with a higher risk of preterm birth and potentially lower birthweight​ (Qian 2020)​. Exposure to particulate matter during pregnancy has also been associated with varying impacts on birthweight, with some studies showing decreased birthweight when exposure occurs in the second trimester​ (Bell 2010)​. Additionally, maternal smoking during pregnancy, particularly in the context of higher stress and anxiety, is significantly associated with low birth weight​ (Schechter 2020)​. These findings underscore the complex interplay between environmental factors and maternal lifestyle during pregnancy on fetal development.

Our research question is crucial for several reasons. Understanding how various prenatal lifestyles and chemical exposures affect birthweight is vital for improving public health outcomes. Low birthweight has been linked to numerous adverse health effects, such as increased risk of infant mortality and chronic diseases in later life, like diabetes and heart disease(Negrato 2013). Moreover, identifying these factors can guide public health policies and interventions aimed at minimizing harmful exposures during pregnancy, ultimately enhancing maternal and child health. Furthermore, a data-driven approach can provide objective, quantifiable insights that are essential for developing targeted, evidence-based healthcare strategies.

```{r library, include=FALSE}
library(tidyverse)
library(caret)
library(rpart.plot)
library(vcd)
library(reshape2)

```

# Research Question

Our research question is to generate a hypotheses regarding a wide range of prenatal lifestyles and chemical exposures affect birth outcome(measured by birthweight) using data-driven methods. 

# Load .Rdata file and Data Preparation
rexpose package were introduced here in hope of characterization more easily. But it seemed too rigid to be applied to datasets containing both continuous and categorical variables. So I only deal with continuous exposome with this package.

```{r data preparation, warning=FALSE, message=FALSE}
library(rexposome)
args(loadExposome)

# Load data using path of where file is stored
load("exposome.RData")

# modify the dataframes to fit with the data format required by package 'rexposome'.
## merge covariates and phenotype, phenotype only has birthweight.
phenotype = phenotype |> select(ID, e3_bw)
cov_phe = inner_join(covariates, phenotype, by = "ID")

## I am planning on exploring the effect of prenatal exposome towards babies' birth weight. So I just removed all postnatal exposure.


### tailor exposome into all continuous prenatal exposome, corresponding with codebook
pre = codebook |> filter(period == "Pregnancy")
name = rownames(pre)
pre_exp = exposome |> select(ID,any_of(name)) 
pre_exp_cont = pre_exp |> select(where(is.numeric))
filtered_name = colnames(pre_exp_cont) 
### tailor the codebook(description containing all prenatal exposome description info, including family-each row is an exposure)
exp_description <- codebook |>  filter(variable_name %in% filtered_name) 
### Since codebook's row name was originally the exposure names, I just removed the 'variable name' column 
exp_description <- exp_description[,-1]
### let ID be pre_exp's rowname and remove the id column
rownames(pre_exp) <- pre_exp_cont[,1]
pre_exp_cont <- pre_exp_cont[,-1]
### let ID be cov_phe's rowname and remove the id column
rownames(cov_phe) <- cov_phe[,1]
cov_phe <- cov_phe[,-1]


# get the object fit with rexposome
exp <- loadExposome(
    exposures = pre_exp_cont, 
    description = exp_description, 
    phenotype = cov_phe
)
# give an overall look at the exposome of interest
skimr::skim(pre_exp)
```

# Data Exploration

## 1. Covariates and phenotypes
1. Since this dataset is a combine data from 6 cohorts, I would explore population characteristics(covariates) and outcomes(phenotypes) by cohorts.
```{r missing1}
plotMissings(exp, set = "phenotypes")
#tableMissings(exp, set = "phenotypes", output = "n")
```

### categorical variables

```{r cate_cov_phe, warning=FALSE, message=FALSE}
cate_cov_phe = cov_phe |> select(where(is.factor))

# Frequency table
frequency_tables_cov_phe <- cate_cov_phe %>% map(~ as.data.frame(table(.x)))
frequency_tables_cov_phe |>knitr::kable()# name of variables in these freq tables are displayed in the plot below

# Difference by cohort
cate_cov_phe_summ = cate_cov_phe %>%
  pivot_longer(cols = -h_cohort, names_to = "covariate", values_to = "value") %>%
  group_by(h_cohort, covariate,value) %>%
  summarize(n = n(), .groups = 'drop') %>%
  ungroup() 

cate_cov_phe_summ %>%
  ggplot(aes(x = h_cohort, y = n, color = value)) +
  geom_point() +
  geom_smooth(aes(group=value), method = "loess", se = FALSE) + 
  facet_grid(. ~ covariate) +
  theme_minimal() +  # For a cleaner look
  labs(x = "Cohort", y = "Count", title = "Summary by Cohort and Covariate") 

```

### continuous variables

```{r cont_cov_phe}

cont_cov_phe = cov_phe|> select(where(is.numeric))

summary_table_cov_phe <- cont_cov_phe %>%
  summarise(across(where(is.numeric), list(
    Mean = ~mean(.x, na.rm = TRUE),
    SD = ~sd(.x, na.rm = TRUE),
    Median = ~median(.x, na.rm = TRUE),
    IQR = ~IQR(.x, na.rm = TRUE)
  ))) |>
  pivot_longer(
    cols = everything(), 
    names_to = c(".value", "Statistic"), 
    names_pattern = "(.*)_(.*)"
  ) 
summary_table_cov_phe|> knitr::kable()

# I specify the continuous variables' names in 'name' vector to add h_cohort in this dataset(I want to assess if there's difference between cohorts-especially the exposome)
name_cont_cov_phe = colnames(cont_cov_phe)[-1]
results_cov_phe = cov_phe |> select(h_cohort, any_of(name_cont_cov_phe))

results_summary_cov_phe = results_cov_phe %>%
  group_by(h_cohort) %>%
  summarize(across(where(is.numeric), 
                   list(mean = ~mean(.x, na.rm = TRUE), 
                        std = ~sd(.x, na.rm = TRUE)))) 

# Since birthweight is too large(also my outcome), I displayed it separately.
results_cov_phe |> ggplot(aes(x=h_cohort, y=e3_bw)) + geom_boxplot() +
  labs(x = "Cohort", y = "Birthweight(g)", title = "Birthweight of children by Cohort") 

results_cov_phe_nobw = results_cov_phe |> select(-e3_bw)

# difference across cohorts
results_melted_cov_phe = melt(results_cov_phe_nobw)
results_melted_cov_phe |>
  ggplot(aes(x=h_cohort, y=value, fill=variable)) + geom_boxplot() + facet_wrap(~variable)+
  labs(x = "Cohort", y = "Covariates and phenotypes", title = "Covariates and phenotypes by Cohort") 

```

## 2. Exposome

2. Look at the exposome characteristics by family and the correlation between exposome

```{r missing2}
#tableMissings(exp, set = "exposures", output = "n")
plotMissings(exp, set = "exposures")

```
The current exposome data has no missing in the exposures nor in the phenotypes


### continuous
```{r}
# exposome behavior
# plotFamily(exp, family = "all") generate error message, I don't know why, the for loop didn't work either. it seemed like the 'build environment' had a mixed falimy
plotFamily(exp, family = "Air Pollution")
# plotFamily(exp, family = "Built environment")
plotFamily(exp, family = "Metals")
plotFamily(exp, family = "Meteorological")
plotFamily(exp, family = "Natural Spaces")
plotFamily(exp, family = "Noise")
plotFamily(exp, family = "Organochlorines")
plotFamily(exp, family = "Organophosphate pesticides")
plotFamily(exp, family = "Polybrominated diphenyl ethers (PBDE)")
plotFamily(exp, family = "Per- and polyfluoroalkyl substances (PFAS)")
plotFamily(exp, family = "Phenols")
plotFamily(exp, family = "Phthalates")
plotFamily(exp, family = "Tobacco Smoke")
plotFamily(exp, family = "Traffic")
plotFamily(exp, family = "Water DBPs")

# exposome are not normally distributed
nm <- normalityTest(exp)
table(nm$normality)

# correlation
exp_cr <- correlation(exp, use = "pairwise.complete.obs", method.cor = "pearson")
plotCorrelation(exp_cr, type = "circos")
plotCorrelation(exp_cr, type = "matrix")
```

# Prepare datasets
```{r final_dataset}
# merge features together
feature = merge(pre_exp,covariates,by="ID") |> select(-c(hs_c_height_None, hs_c_weight_None, hs_child_age_None))
outcome = phenotype |> select(ID, e3_bw)
studydata = merge(feature,outcome,by="ID") 

# keep all interested features, no matter continuous or categorical, in a new dataframe 'rf_ln' for random forest algorithm and classic linear regression 
rf_ln = studydata |> select(-ID)


# transform all categorical variables into dummy variables and keep all features in a dataframe 'la_data' for lasso algorithm
# One-hot encode the categorical variables
la_data <- dummyVars("~ .", data = rf_ln)
la_data <- data.frame(predict(la_data, newdata = rf_ln))
```


# PCA to reduce dimensionality(create a new variable) 

We reduced the dimensionality by conducting a separate PCA within each of the 19 pre-defined exposure groups, and retained only the first principal component for all of them. In this analysis, a composite index variable was created for each exposure group and then averaged by cohort to compare the levels. This approach significantly simplifies the data, facilitating the examination of key patterns and relationships between exposome exposures and birth weight outcomes across different groups. (https://www.sciencedirect.com/science/article/pii/S0160412018316295#t0005)


```{r}
library(FactoMineR)


# get all family of exposome
pre_exp_grp = codebook |> filter(period=="Pregnancy" & !(family %in% c("Covariates", "Phenotype")))
exp_groups = unique(pre_exp_grp$family)

# Transform the nominal variables into binary variables using the dummy variable object
dummies_pre_exp <- dummyVars("~ .", data = pre_exp)
pre_exp_transformed <- data.frame(predict(dummies_pre_exp, newdata = pre_exp))

# Delete the id column of pre_exp
pre_exp_transformed_noid = pre_exp_transformed |> select(-ID)

# conduct PCA within each family iteratively and get a composite index variable (principal component scores) for each exposure group
for (family in exp_groups){
  
  ori_comp_names = codebook |> filter(family==family) |> pull(variable_name)
  ori_comp = pre_exp_transformed_noid |> select(matches(paste0("^", ori_comp_names, ".*")))
  res.pca <- PCA(ori_comp, scale.unit = TRUE, ncp = 5, graph = FALSE)

  # Extracting the first principal component scores
  pc1_scores <- res.pca$ind$coord[, 1]
}


# Add the PCA score to the whole dataset with cohort info
studydata$pc1_score <- pc1_scores

# Averaging the PCA scores by cohort
average_scores_by_cohort <- studydata %>%
  group_by(h_cohort) %>%
  summarise(Average_pc1_Score = mean(pc1_scores, na.rm = TRUE))

average_scores_by_cohort
```

 **In a nutshell, the final dataset 'rf_ln' has 1 outcome *e3bw*, 10 covariates that were know at birth(excluding hs_c_height_None, hs_c_weight_None, hs_child_age_None) and 88 prenatal exposures.** There's no missing or duplicate in this dataset. All variables were correctly classified as numeric or factor. **To better application of some algorithms, some transformation of the dataset is needed(e.g. 'la_data')** 
 
EDA findings:

1. Some covariates (e.g. education and nativity of parents) might different across cohorts. We should assess the heterogenitity before we could pool the data from six cohorts. But due  to limited time, I just assumed that we can pool them together and continue the further application od machine learning.

2. exposomes vary in their level even though they are from the same family, so we need to do centering and scaling. Using a innovative methods of PCA, we can compare the overall level of exposome to see if there's cohort effect. 

3. More detail on PCA that created a new variable that not involved in our main analysis:

By conducting PCA separately within each family, we aimed to:

* Reduce Dimensionality: We extracted the first principal component (PC) from each family to summarize the key variance within that family. This step reduces the complexity of the dataset while retaining critical information.
* Increase Comparability and Interpretability: Separate PCAs allowed the researchers to better understand and interpret the main drivers of variability within each exposure family. This approach helps in comparing levels of exposure across different cohorts.


```{r partition}
#Partition data for use in demonstration
set.seed(123)
train.indices<-createDataPartition(y=rf_ln$e3_bw,p=0.7,list=FALSE)
train.data<-rf_ln[train.indices, ]
test.data<-rf_ln[-train.indices, ]

set.seed(123)
control <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
```


# LASSO

```{r lasso}
la.model<- train(
                  e3_bw ~., 
                  data = train.data, 
                  method = "glmnet",
                  trControl =  control, 
                  preProc = c("center", "scale"),
                  tuneGrid = expand.grid(alpha = 1, 
                                         lambda = exp(seq(3, -3, length = 100)))
                )

coef(la.model$finalModel, la.model$bestTune$lambda)

print(la.model$bestTune)
print(la.model$results$RMSE[which.min(la.model$results$RMSE)])

```



# Random Forest


```{r random forest}
# For random forest with lots of features, mtry = p(the number of all features)/3 tend to be a good default mtry for regression. mtry = sqrt(p) is a good default for classification. (https://scholarworks.utep.edu/cgi/viewcontent.cgi?article=4251&context=open_etd)

feat.count<-c(ncol(rf_ln)/3, ncol(rf_ln)/2, ncol(rf_ln)-1)

grid.rf<-expand.grid(mtry=round(feat.count))

tree.num<-seq(100,500, by=200)

results.trees<-list()

for (ntree in tree.num){
 set.seed(123)
  rf.model<-train(e3_bw ~ ., 
                 data=train.data, 
                 method="rf", 
                 metric="RMSE", 
                 tuneGrid=grid.rf, 
                 importance=TRUE, 
                 ntree=ntree)
index<-toString(ntree)
results.trees[[index]]<-rf.model$results
}
plot(rf.model)
rf.model$results


output.rf<-bind_rows(results.trees, .id = "ntrees")
best.tune<-output.rf[which.max(output.rf[,"mtry"]==50),]
best.tune$mtry
mtry.grid<-expand.grid(.mtry=best.tune$mtry)
set.seed(123)
    rf.model.bt<-train(
                      e3_bw~., 
                      data=train.data, 
                      method="rf", 
                      trControl=control, 
                      metric="RMSE", 
                      tuneGrid=mtry.grid, 
                      importance=TRUE,
                      ntree=as.numeric(best.tune$ntrees))

    


rf.model.bt$results
rf.model.bt$finalModel
varImp(rf.model.bt)
plot(varImp(rf.model.bt))
```

Although when mtry is close to the number of all features(p), RMSE is the lowest. But it increases the risk of overfitting. What's more, values of mtry that are close to the total number of variables in the model may weaken the forest by making the individual decision trees more correlated; when the decision trees consider similar sets of variables to split on, they are more likely to be similar, even if each is fit to a different bootstrapped data set. Ensemble models usually strive for independence of their members, as that improves predictive ability. We can also see from the plot that the decreasing trend of RMSE flattened after 50. I would choose 50 as my final mtry.


# Linear regression 

```{r linear_reg}

# Initialize a model with all predictors
intercept.model <- lm(e3_bw ~ ., data = rf_ln)

# Both-direction stepwise regression
ln.model <- step(intercept.model, direction = "both", trace = 0)

summary(ln.model)

set.seed(123)


linear.model <- train(
  e3_bw ~ h_fdensity300_preg_Log + h_frichness300_preg_None + 
    h_walkability_mean_preg_None + h_dairy_preg_Ter + h_folic_t1_None + 
    h_meat_preg_Ter + h_pamod_t3_None + hs_cs_m_Log2 + h_temperature_preg_None + 
    hs_dde_madj_Log2 + hs_pcb170_madj_Log2 + hs_dep_madj_Log2 + 
    hs_dmtp_madj_Log2 + hs_pfos_m_Log2 + hs_bupa_madj_Log2 + 
    hs_mepa_madj_Log2 + hs_meohp_madj_Log2 + hs_mibp_madj_Log2 + 
    hs_mnbp_madj_Log2 + e3_asmokcigd_p_None + h_bro_preg_Log + 
    h_cohort + e3_sex_None + h_mbmi_None + hs_wgtgain_None + 
    e3_gac_None + h_edumc_None + h_parity_None,
  data = train.data,
  method = "lm",
  trControl = control,
  preProcess = c("center", "scale")
)

linear.model$results

  
```

# Model Comparasion

The RMSE (Root Mean Squared Error) values for the LASSO, Random Forest, and Linear Regression algorithms were 405.02, 422.12, and 400.98 respectively. RMSE measures the average magnitude of the errors between predicted and actual values, with a lower RMSE indicating better model performance. Among the three, Linear Regression achieved the lowest RMSE, suggesting its superior predictive accuracy for birth weight. This superiority is further supported by comparing R-squared values, which represent the proportion of the variance in the dependent variable that is predictable from the independent variable(s). The R-squared values for Random Forest and Linear Regression were 0.2907 and 0.3571 respectively. Since a higher R-squared value indicates better model performance, the higher R-squared of the Linear Regression model confirms its effectiveness in explaining the variation in birth weight outcomes. Based on these evaluations of RMSE and R-squared values, Linear Regression is the optimal model among the three for predicting birth weight.

```{r Predictions on the test set}
predictions <- predict(linear.model, test.data)
```

```{r Evaluate the model}
results <- postResample(predictions, test.data$e3_bw)
results
```

```{r visualization_linear}

ggplot(data = test.data, aes(x = e3_bw, y = predictions)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", col = "blue") +
  labs(x = "Actual Birthweight", y = "Predicted Birthweight", title = "Linear Model Predictions vs Actual")
```

Model Fit: The fact that the majority of points are clustered around the line suggests that there is a moderate to strong positive linear relationship between the actual and predicted birthweights. However, the model is not perfect, which is expected in most real-world scenarios.
There is some variability in the predictions, as indicated by the scatter of points around the line. Notably, the model seems to underpredict for lower actual birthweights and overpredict for higher actual birthweights, as evidenced by the points below the line on the left and above the line on the right.

# Limitation

**Treatment of Categorical Variables**

In our analysis, we utilized Lasso regression. However, a notable limitation of Lasso regression is its general ineffectiveness with categorical variables. This is due to the method's tendency to select only one level of a categorical variable, ignoring the others, which can lead to biased or misleading results.

One of the potential solution is transformed all categorical variables into dummy variables using the one-hot encoding method. This technique converts each category level into a new binary variable (0 or 1), allowing Lasso to treat each level as a separate feature. However, this approach increases the dimensionality of the data, which can still be problematic for Lasso regression due to its propensity to select an arbitrary subset of correlated dummy variables, potentially omitting important information.
To further refine our model, we implemented group Lasso, a variation of Lasso that enhances its feature selection process by grouping related features together. In our case, dummy variables derived from the same categorical variable were grouped, ensuring that either all or none of the dummy variables in a group were selected. This method helps preserve the integrity of the categorical data structure, maintaining the complete set of information provided by each categorical variable while still benefiting from the regularization and feature selection properties of Lasso. This approach also aids in mitigating the risk of overfitting by reducing the model's complexity, providing a more robust analysis of feature importance relative to our outcome of interest.


**Model Interpretability**
While our final model, linear regression, provides interpretability, it can potentially oversimplify the association between prenatal factors and birth weight, especially if there are interactions between variables or the association is not linear. Hence, to address this problem, a more flexible model should be considered to apply, such as random forest and generalized additive models (GAMs). However, it's crucial to balance model complexicity with interpretability. 

**Causal Inference**
The final model, linear regression, is only eligible to identify associations between prenatal factors and birth weight, which fail to determine causal inference. An alternative method to strengthen casual relationship between prenatal factors and birth weight is to apply advanced casual inference methods, such as propensity score matching, or conducting a longitudinal research. These methods enable more robust and reliable conclusions regarding causal relationships between variables.

**Ethical Concerns**

Data privacy and potential stigamatized certain populations.
Exposome research involves collecting extensive personal and environmental data from participants, including personal sensitive information in lifestyle choices, environmental exposures, and genetic data. Ensuring the privacy and confidentiality of this data is crucial. Therefore, the handling, storage, and processing of such data should comply with legal regulations and ethical standards to protect participants' privacy. Moreover, findings from studies investigating the impact of environmental and lifestyle factors on birth weight could potentially lead to stigmatization of individuals or groups. For instance, if particular behaviors or environmental exposures linked to lower birth weights are prevalent in specific population, these groups might face stigma or discrimination. Therefore, it's important to handle such information sensitively, emphasizing that these findings are not indicative of individual or collective fault and should be used to inform better health policies and interventions. Additionally, there may be bias related to the selection of study participants. For instance, our study participants have a higher likelihood to have access to smart phones and internet, hence it may not accurately represent the entire population of the studied area. Consequently, individuals without these resources—who were not included in the study—might become further marginalized and underrepresented in research that uses machine learning approaches.

# Reference
Qian, Y., Shao, H., Ying, X., Huang, W., & Hua, Y. (2020). The Endocrine Disruption of Prenatal Phthalate Exposure in Mother and Offspring. Frontiers in public health, 8, 366. https://doi.org/10.3389/fpubh.2020.00366

Bell, M. L., Belanger, K., Ebisu, K., Gent, J. F., Lee, H. J., Koutrakis, P., & Leaderer, B. P. (2010). Prenatal exposure to fine particulate matter and birth weight: variations by particulate constituents and sources. Epidemiology (Cambridge, Mass.), 21(6), 884–891. https://doi.org/10.1097/EDE.0b013e3181f2f405

Schechter, J., Do, E. K., Zhang, J. J., Hoyo, C., Murphy, S. K., Kollins, S. H., & Fuemmeler, B. (2020). Effect of Prenatal Smoke Exposure on Birth Weight: The Moderating Role of Maternal Depressive Symptoms. Nicotine & tobacco research : official journal of the Society for Research on Nicotine and Tobacco, 22(1), 40–47. https://doi.org/10.1093/ntr/nty267

Negrato, C. A., & Gomes, M. B. (2013). Low birth weight: causes and consequences. Diabetology & metabolic syndrome, 5, 49. https://doi.org/10.1186/1758-5996-5-49 (Retraction published Diabetol Metab Syndr. 2014;6:60)


