---
title: "P8451_HW10_ML"
author: "Ruixi Li"
date: "2024-03-26"
output: html_document
---

```{r library, include=FALSE}
library(tidyverse)
library(caret)
library(rpart.plot)
library(vcd)
library(reshape2)

```

# Research Question

My research question is to generate a hypothesis of which factors among a wide range of prenatal lifestyles and chemical exposures affect birth outcome(measured by birthweight) using data-driven  methods. (Although I propose my research question after conducting EDA, I would put my research question on the top)

# Load .Rdata file and Data Preparation

```{r data preparation, warning=FALSE, message=FALSE}
# Load data using path of where file is stored
load("exposome.RData")

# I am planning on exploring the effect of prenatal exposome towards babies' birth weight. So I just removed all postnatal exposure.

codebook|> group_by(period) |> count()
pre = codebook |> filter(period == "Pregnancy") 
name = rownames(pre)
pre_exp = exposome |> select(ID,any_of(name))


```

# Data Exploration

 
1. Since this dataset is a combine data from 6 cohorts, I would explore population characteristics(covariates) and outcomes(phenotypes) by cohorts.

2. Correlation between exposures

## 1. Covariates and phenotypes
```{r covariates}
cov_phe = inner_join(covariates, phenotype, by = "ID")
```

### categorical variables

```{r cate_cov_phe, warning=FALSE, message=FALSE}
cate_cov_phe = cov_phe |> select(where(is.factor))

# Frequency table
frequency_tables_cov_phe <- cate_cov_phe %>% map(~ as.data.frame(table(.x)))
frequency_tables_cov_phe |>knitr::kable()# name of variables in these freq tables are displayed in the plot below

# Difference by cohort
cate_cov_phe_summ = cate_cov_phe %>%
  pivot_longer(cols = -h_cohort, names_to = "covariate", values_to = "value") %>%
  group_by(h_cohort, covariate,value) %>%
  summarize(n = n(), .groups = 'drop') %>%
  ungroup() 

cate_cov_phe_summ %>%
  ggplot(aes(x = h_cohort, y = n, color = value)) +
  geom_point() +
  geom_smooth(aes(group=value), method = "loess", se = FALSE) + 
  facet_grid(. ~ covariate) +
  theme_minimal() +  # For a cleaner look
  labs(x = "Cohort", y = "Count", title = "Summary by Cohort and Covariate") 





```

### continuous variables

```{r cont_cov_phe}

cont_cov_phe = cov_phe|> select(where(is.numeric))

summary_table_cov_phe <- cont_cov_phe %>%
  summarise(across(where(is.numeric), list(
    Mean = ~mean(.x, na.rm = TRUE),
    SD = ~sd(.x, na.rm = TRUE),
    Median = ~median(.x, na.rm = TRUE),
    IQR = ~IQR(.x, na.rm = TRUE)
  ))) |>
  pivot_longer(
    cols = everything(), 
    names_to = c(".value", "Statistic"), 
    names_pattern = "(.*)_(.*)"
  ) 
summary_table_cov_phe|> knitr::kable()

# I specify the continuous variables' names in 'name' vector to add h_cohort in this dataset(I want to assess if there's difference between cohorts-especially the exposome)
name_cont_cov_phe = colnames(cont_cov_phe)[-1]
results_cov_phe = cov_phe |> select(h_cohort, any_of(name_cont_cov_phe))

results_summary_cov_phe = results_cov_phe %>%
  group_by(h_cohort) %>%
  summarize(across(where(is.numeric), 
                   list(mean = ~mean(.x, na.rm = TRUE), 
                        std = ~sd(.x, na.rm = TRUE)))) 

# Since birthweight is too large(also my outcome), I displayed it separately.
results_cov_phe |> ggplot(aes(x=h_cohort, y=e3_bw)) + geom_boxplot() +
  labs(x = "Cohort", y = "Birthweight(g)", title = "Birthweight of children by Cohort") 

results_cov_phe_nobw = results_cov_phe |> select(-e3_bw)

# difference across cohorts
results_melted_cov_phe = melt(results_cov_phe_nobw)
results_melted_cov_phe |>
  ggplot(aes(x=h_cohort, y=value, fill=variable)) + geom_boxplot() + facet_wrap(~variable)+
  labs(x = "Cohort", y = "Covariates and phenotypes", title = "Covariates and phenotypes by Cohort") 
  


```

## 2.Exposome(pre exp)

### Categorical

```{r cate_exp, warning=FALSE, message=FALSE}

cate_exp = pre_exp |> select(where(is.factor))
## Correlations
### Function to calculate Cramér's V
cramers_v <- function(x, y) {
  tbl <- table(x, y)
  chi2 <- chisq.test(tbl, correct = FALSE)$statistic
  n <- sum(tbl)
  phi2 <- chi2 / n
  r <- nrow(tbl) - 1
  k <- ncol(tbl) - 1
  min_rk <- min(r, k)
  v <- sqrt(phi2 / min_rk)
  return(v)
}

### Create an empty matrix to store the results
vars <- names(cate_exp)
n <- length(vars)
cramer_matrix <- matrix(NA, n, n, dimnames = list(vars, vars))

### Calculate Cramér's V for every pair of variables
for (i in 1:n) {
  for (j in 1:n) {
    cramer_matrix[i, j] <- cramers_v(cate_exp[[i]], cate_exp[[j]])
  }
}

### Replace diagonals with 0 for better visualization
diag(cramer_matrix) <- 0

melted_cramer_matrix <- melt(cramer_matrix)

ggplot(melted_cramer_matrix, aes(Var1, Var2, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0.5, limit = c(0,1), space = "Lab", name="Cramér's V") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
        axis.title = element_blank()) +
  labs(fill = "Cramér's\nV")
```


### Categorical

```{r cont_exp, warinng=FALSE, message=FALSE}
cont_exp = pre_exp |> select(where(is.numeric)) |> select(-ID)

## Correlation
## Calculate correlation matrix
cor_matrix <- cor(cont_exp, use = "complete.obs")

### Replace diagonals with 0 for better visualization
diag(cor_matrix) <- 0



# Melt the correlation matrix
melted_cor_matrix <- melt(cor_matrix)

# Plotting
ggplot(melted_cor_matrix, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Pearson\nCorrelation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, size = 12, hjust = 1),
        axis.text.y = element_text(size = 12)) +
  coord_fixed() +
  labs(x = '', y = '', title = 'Correlation Matrix Heatmap')
```

# Merge datasets
```{r final_dataset}
# merge features together
feature = merge(pre_exp,covariates,by="ID")
outcome = phenotype |> select(ID, e3_bw)
studydata = merge(feature,outcome,by="ID") 

|>
  select(-c(hs_c_weight_None, hs_c_height_None, hs_child_age_None)) |>
  select(-ID)

skimr::skim(studydata)

```

* There's 6 phenotype in 'phenotype' dataset, 13 covariates in 'covariates' dataset and 88 prenatal exposures in 'pre_exp' dataset, which I would focus on. According to my research question, I would keep only one phenotype *e3_bw*(birthweight) as my outcome. Also, since this study don't focus on postnatal period, I would remove *hs_c_height_None*(Height of the child at 6-11 years old (m)), *hs_c_weight_None*(Weight of the child at 6-11 years old (kg)),*hs_child_age_None*(Child age at examination (years)) from my covariates list that I 
would control for. They were the only three variables in 'covariates' dataset that are highly correlated with each other. **In a nutshell, the final dataset 'studydata' had 1 identifier *ID*, 1 outcome *e3bw*, 10 covariates and 88 prenatal exposures.** There's no missing and duplicate in this dataset. All variables were correctly classified as numeric or factor. 

* Some covariates and exposores are different across cohorts(I didn't do hypothesis testing, I just used visual inspection). We should assess the heterogenitity before we could pool the data from 6 cohots. But due to limited time, I just assumed that we can pool them together.

# PCA to reduce dimensionality
We reduced the dimensionality by conducting a separate PCA within each of the 19 pre-defined exposure groups, and retained only the first principal component for all of them. This way, we created a composite index variable (principal component scores) for each exposure group, and then averaged the scores by cohort to compare the levels.

```{r}
library(FactoMineR)
library(factoextra)
exp_groups = unique(codebook$family)
exp_groups = exp_groups[-20]


for (family in exp_group){
  feature
  # Assuming `data_group` is your dataframe for one exposure group
  res.pca <- PCA(data_group, scale.unit = TRUE, ncp = 5, graph = FALSE)

  # Extracting the first principal component scores
  pc1_scores <- res.pca$ind$coord[, 1]
}


```



# Implement Elastic Net Algorithm 

```{r partition}
#Partition data for use in demonstration
set.seed(123)
train.indices<-createDataPartition(y=studydata$e3_bw,p=0.7,list=FALSE)
train.data<-studydata[train.indices, ]
test.data<-studydata[-train.indices, ]
```


```{r}
set.seed(123)
control = trainControl(method = "repeatedcv", 
                      number = 10,
                      repeats = 5,
                      selectionFunction = "best")


# Model building
en.model<- train(
                  e3_bw ~., 
                  data = train.data, 
                  method = "glmnet",
                  trControl =  control, 
                  preProc = c("center", "scale"),
                  tuneGrid = expand.grid(alpha = seq(0, 1, length = 20), 
                                         lambda = exp(seq(3, -3, length = 100)))
                )
# I chose tuneGrid here, because this command can be used for different scenarios,but using TuneLength, I have to look at all results and see which k is the best. 

#Print the values of alpha and lambda that gave best prediction
en.model$bestTune


# Model coefficients
coef(en.model$finalModel, en.model$bestTune$lambda)

resamp = en.model$resample


# Predictions for models
prediction = predict(en.model, test.data)

# Evaluation
RMSE(prediction, test.data$e3_bw)
R2(prediction, test.data$e3_bw)

```

* Elastic Net Algorithm were applied to training dataset, with the best hyperparameter of alpha = 1,lambda ~ 13.14. This is a lasso model and can select features. Finally, only 34 variables are kept in the model. testing RMSE is `r RMSE(prediction, test.data$e3_bw)` and testing R2 is `r R2(prediction, test.data$e3_bw)`.

# Interaction

```{r interaction, message=FALSE, warning=FALSE}
set.seed(123)

model_interaction <- train(
                  e3_bw ~ (h_pm10_ratio_preg_None+h_dairy_preg_Ter+h_fastfood_preg_Ter+h_folic_t1_None+h_pamod_t3_None+h_pavig_t3_None+h_veg_preg_Ter+hs_as_m_Log2+hs_cd_m_Log2+hs_cs_m_Log2+hs_cu_m_Log2+hs_tl_mdich_None+h_ndvi100_preg_None+hs_dep_madj_Log2+hs_dmtp_madj_Log2+hs_pbde47_madj_Log2+hs_pfna_m_Log2+hs_pfoa_m_Log2+hs_etpa_madj_Log2+hs_oxbe_madj_Log2+hs_oxbe_madj_Log2+hs_mibp_madj_Log2+e3_asmokcigd_p_None+hs_cotinine_mcat_None+h_trafnear_preg_pow1over3+h_bro_preg_Log+e3_sex_None+h_mbmi_None+hs_wgtgain_None+e3_gac_None+h_edumc_None+h_native_None+h_parity_None)^2, 
                  data = train.data, preProcess=c("center", "scale"), 
                  method = "glmnet",
                  trControl = control,
                  expand.grid(alpha = seq(0, 1, length = 20), 
                                         lambda = exp(seq(3, -3, length = 100)))
               )

library(doParallel)
registerDoParallel(cores = detectCores())

#Print the values of alpha and lambda that gave best prediction
model.3$bestTune

#Examine model coefficients for variable importance
coef(model.3$finalModel, model.3$bestTune$lambda)

#Predict in test-set
model.3.pred <- model.3 %>% 
                predict(test.data)

# Evaluation metrics and prediction performance
data.frame(
            RMSE = RMSE(model.3.pred, test.data$e3_bw),
            Rsquare = R2(model.3.pred, test.data$e3_bw)
          )
```

